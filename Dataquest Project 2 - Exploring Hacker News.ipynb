{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Analysis\n",
    "\n",
    "This Dataquest task requires me to anaylze Hacker News posts to figure out, out of two types of posts (`Ask HN` and `Show HN`) which receives the most comments, and at what time of day posts receive the most comments overall. \n",
    "\n",
    "This will test some cleaning and importing, but mainly date/time manipulation from some recent packages you'll see below.\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header:\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      " \n",
      "Body:\n",
      "[['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n",
      " \n",
      "Length of dataset: [20100]\n"
     ]
    }
   ],
   "source": [
    "#Import.\n",
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "HN = list(read_file)\n",
    "\n",
    "#Splitting header and body into two.\n",
    "headers = HN[0]\n",
    "HN = HN[1:]\n",
    "\n",
    "print(\"Header:\")\n",
    "print(headers)\n",
    "print(\" \") #Maybe there's a better way of doing this\n",
    "print(\"Body:\")\n",
    "print(HN[3:5])\n",
    "print(\" \")\n",
    "print(\"Length of dataset:\", [len(HN)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "Header and data have been split, so now let's filter the data to find our `Ask HN` and `Show HN`, while removing everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Ask HN: 1744\n",
      "Length of Show HN: 1162\n",
      "Length of others: 17194\n",
      " \n",
      "Length check: 20100 vs. 20100\n"
     ]
    }
   ],
   "source": [
    "#Create three empty lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#Loop through to each list\n",
    "for posts in HN:\n",
    "    title = posts[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(posts)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(posts)\n",
    "    else:\n",
    "        other_posts.append(posts)\n",
    "    \n",
    "print(\"Length of Ask HN:\", len(ask_posts))\n",
    "print(\"Length of Show HN:\", len(show_posts))\n",
    "print(\"Length of others:\", len(other_posts))\n",
    "print(\" \")\n",
    "print(\"Length check:\", len(ask_posts)+len(show_posts)+len(other_posts), \"vs.\", len(HN)) #Surely a bad way of doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our total matches the above figure, and we've split the list out ensuring that we'll include both upper and lower cases if the posts were different.\n",
    "\n",
    "## Analysis 1: Average number of comments per post type\n",
    "Cleaning over, let's analyze `Ask HN` and `Show HN` to see which gets more comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of Ask HN comments: 14.04\n",
      "Average number of Show HN comments: 10.32\n",
      "\n",
      "Ask HN posts get 3.72 more comments on average.\n"
     ]
    }
   ],
   "source": [
    "#Variables starting with 0:\n",
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "#Iterate over ask and convert to integer, add those to the empty variable\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts) #Make an average\n",
    "avg_ask_comments = round(avg_ask_comments, 2) #Let's tidy this up\n",
    "\n",
    "print(\"Average number of Ask HN comments:\", avg_ask_comments)\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])    \n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "avg_show_comments = round(avg_show_comments, 2)\n",
    "\n",
    "print(\"Average number of Show HN comments:\", avg_show_comments)\n",
    "print(\"\")\n",
    "\n",
    "difference = avg_ask_comments - avg_show_comments\n",
    "difference = round(difference, 2)\n",
    "print(\"Ask HN posts get\", difference, \"more comments on average.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2: What time gets the most comments?\n",
    "`Ask HN` posts are the overall winner. People like to be asked things, and less so like to comment on things others have done. Incredible.\n",
    "\n",
    "But what time are people most likely to answer questions? Let's find out in a couple of steps:\n",
    "\n",
    "First, I'll calculate the amount of `Ask HN` posts created at each hour of the day. This includes the number of comments received.\n",
    "\n",
    "Second, I'll calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "We're going to work with the datetime package to make analysis of date strings somewhat better. But before that, I'll make a results list which isolate comments by the number of comments and when they were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "#This was done in a single line elsewhere but I've added variables\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    created_at = post[6]\n",
    "    result_list.append([created_at, num_comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use datetime (and our new friends strptime and strftime) to parse these strings into a date format, then represent only the hour.\n",
    "\n",
    "(I've only used these ONCE before in learning, so this code was mainly copied over from an answer and then edited to make more clear for myself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\" #Clever way of simplifying\n",
    "\n",
    "for row in result_list:\n",
    "    created_at = row[0]\n",
    "    number_of_comments = row[1]\n",
    "    hour = dt.datetime.strptime(created_at, date_format).strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = number_of_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += number_of_comments\n",
    "        \n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now seen, by hour, the total number of comments created. Clearly, `15`, or 3 o'clock, is the time most posters are active. But for analysis, let's average the times anyway. (2 a.m. is also a curious outlier).\n",
    "\n",
    "To calculate the average, we use a special technique:\n",
    "\n",
    "1) Create (initialize) an empty list\n",
    "\n",
    "2) Loop (iterate) over the keys of a dictionary and append to the initial list another list with some magic ****ing calculation. These nerds are the worst at explaining what to do sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['03', 7.796296296296297],\n",
       " ['17', 11.46],\n",
       " ['05', 10.08695652173913],\n",
       " ['10', 13.440677966101696],\n",
       " ['04', 7.170212765957447],\n",
       " ['01', 11.383333333333333],\n",
       " ['12', 9.41095890410959],\n",
       " ['09', 5.5777777777777775],\n",
       " ['14', 13.233644859813085],\n",
       " ['20', 21.525],\n",
       " ['21', 16.009174311926607],\n",
       " ['13', 14.741176470588234],\n",
       " ['07', 7.852941176470588],\n",
       " ['22', 6.746478873239437],\n",
       " ['11', 11.051724137931034],\n",
       " ['06', 9.022727272727273],\n",
       " ['02', 23.810344827586206],\n",
       " ['08', 10.25],\n",
       " ['15', 38.5948275862069],\n",
       " ['19', 10.8],\n",
       " ['23', 7.985294117647059],\n",
       " ['18', 13.20183486238532],\n",
       " ['16', 16.796296296296298],\n",
       " ['00', 8.127272727272727]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the analysis\n",
    "\n",
    "The output is unordered, We can see 15 (or 3pm) has the highest average, but it wasn't easy! Let's just spend some time sorting this out for clearer reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.796296296296297, '03']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]]) #Fancy!\n",
    "\n",
    "print(swap_avg_by_hour[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the sorted() function to sort swap_avg_by_hour in descending order.\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "#And this below orders our results by top 5, but we can do better!\n",
    "sorted_swap[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The REAL top five hours for posting\n",
    "\n",
    "Formatted and everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 15:00 there were 38.59 comments per post (on average)\n",
      "At 02:00 there were 23.81 comments per post (on average)\n",
      "At 20:00 there were 21.52 comments per post (on average)\n",
      "At 16:00 there were 16.80 comments per post (on average)\n",
      "At 21:00 there were 16.01 comments per post (on average)\n"
     ]
    }
   ],
   "source": [
    "for avg, hr in sorted_swap[:5]:\n",
    "    print (\"At {} there were {:.2f} comments per post (on average)\".format(\n",
    "            dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"),avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lots of posts at 3 p.m. and 2 a.m. I'd be interested to find out what is getting posted at 2 a.m. that gets so much traffic, but as a business, we'd ruin the 3 p.m. timeslot with 'content marketing'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
